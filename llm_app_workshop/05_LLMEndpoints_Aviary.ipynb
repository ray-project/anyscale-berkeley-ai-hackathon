{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query LLMs with Aviary\n",
    "\n",
    "Anyscale Aviary is a library for serving and querying open source LLMs. \n",
    "\n",
    "This tutorial shows you how to use Aviary to query and chat with LLMs.\n",
    "\n",
    "For this tutorial, we have already set up an Aviary backend. You can use the url and token below to query it.\n",
    "\n",
    "You can view the Aviary source here: https://github.com/ray-project/aviary.\n",
    "\n",
    "## Install\n",
    "\n",
    "You can install the Aviary SDK using the command below. You can configure the SDK\n",
    "using the environment variables shown below to point to the correct backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aviary@ git+https://github.com/ray-project/aviary.git@sdk_update\n",
      "  Cloning https://github.com/ray-project/aviary.git (to revision sdk_update) to /private/var/folders/4j/z6dzqmms4xq0hsbh_7lx59f40000gn/T/pip-install-vqfajt4c/aviary_f65d3b3422b64fe288061b0caa105a16\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ray-project/aviary.git /private/var/folders/4j/z6dzqmms4xq0hsbh_7lx59f40000gn/T/pip-install-vqfajt4c/aviary_f65d3b3422b64fe288061b0caa105a16\n",
      "  Running command git checkout -b sdk_update --track origin/sdk_update\n",
      "  Switched to a new branch 'sdk_update'\n",
      "  branch 'sdk_update' set up to track 'origin/sdk_update'.\n",
      "  Resolved https://github.com/ray-project/aviary.git to commit 97bfec84c4c8fe3d86e459ebbd9b41e66c938367\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.9 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (0.9.0)\n",
      "Requirement already satisfied: rich in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (13.4.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (4.6.3)\n",
      "Requirement already satisfied: requests in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (2.31.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from typer>=0.9->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (8.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from requests->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from requests->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from requests->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from requests->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from rich->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from rich->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (0.1.2)\n",
      "Building wheels for collected packages: aviary\n",
      "  Building wheel for aviary (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aviary: filename=aviary-0.0.2-py3-none-any.whl size=76883 sha256=2cb9e75597d0e2e70a3af2358e6fa9d3c768b283634847f47d0c0646b74cecc3\n",
      "  Stored in directory: /private/var/folders/4j/z6dzqmms4xq0hsbh_7lx59f40000gn/T/pip-ephem-wheel-cache-loxdw1y0/wheels/88/e3/83/9f22ec0fc0ff079fbc83e01ffb66297a9bc3e4d2848cf68086\n",
      "Successfully built aviary\n",
      "Installing collected packages: aviary\n",
      "Successfully installed aviary-0.0.2\n",
      "env: AVIARY_URL=https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com\n",
      "env: AVIARY_TOKEN=aviary++5015ff37-3891-46bd-b066-fe224e48f8fc\n"
     ]
    }
   ],
   "source": [
    "!pip install \"aviary @ git+https://github.com/ray-project/aviary.git@sdk_update\"\n",
    "%env AVIARY_URL=https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com\n",
    "%env AVIARY_TOKEN=aviary++5015ff37-3891-46bd-b066-fe224e48f8fc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the LLM\n",
    "\n",
    "Now that we have configured Aviary, we are ready to query a model. Let's start by viewing which models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mosaicml/mpt-7b-instruct',\n",
       " 'amazon/LightGPT',\n",
       " 'databricks/dolly-v2-12b',\n",
       " 'CarperAI/stable-vicuna-13b-delta',\n",
       " 'OpenAssistant/falcon-7b-sft-top1-696',\n",
       " 'mosaicml/mpt-7b-chat',\n",
       " 'stabilityai/stablelm-tuned-alpha-7b',\n",
       " 'lmsys/vicuna-13b-delta-v1.1',\n",
       " 'mosaicml/mpt-7b-storywriter',\n",
       " 'h2oai/h2ogpt-oasst1-512-12b',\n",
       " 'OpenAssistant/oasst-sft-7-llama-30b-xor']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aviary\n",
    "\n",
    "# View all models available with aviary\n",
    "aviary.models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's query the amazon/LightGPT model and ask it how to make fried rice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_text': \"To make fried rice, start by heating oil in a large skillet over medium-high heat. Add your choice of protein (such as chicken, beef, or tofu) and cook until it's browned. Once cooked through, add your vegetables of choice and stir to combine. Finally, add some soy sauce or other flavorings and let everything simmer for about 5 minutes before serving. Enjoy!\",\n",
       " 'num_input_tokens': 35,\n",
       " 'num_input_tokens_batch': 35,\n",
       " 'num_generated_tokens': 79,\n",
       " 'num_generated_tokens_batch': 79,\n",
       " 'preprocessing_time': 0.0005139989998497185,\n",
       " 'generation_time': 1.2390154719996644,\n",
       " 'postprocessing_time': 0.001852543999120826,\n",
       " 'generation_time_per_token': 0.010868556771926881,\n",
       " 'generation_time_per_token_batch': 0.010868556771926881,\n",
       " 'num_total_tokens': 114,\n",
       " 'num_total_tokens_batch': 114,\n",
       " 'total_time': 1.241382014998635,\n",
       " 'total_time_per_token': 0.010889315921040657,\n",
       " 'total_time_per_token_batch': 0.010889315921040657}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query LightGPT model\n",
    "response = aviary.completions('amazon/LightGPT', 'How do I make fried rice?')\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pretty print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make fried rice, start by heating oil in a large skillet over\n",
      "medium-high heat. Add your choice of protein (such as chicken, beef,\n",
      "or tofu) and cook until it's browned. Once cooked through, add your\n",
      "vegetables of choice and stir to combine. Finally, add some soy sauce\n",
      "or other flavorings and let everything simmer for about 5 minutes\n",
      "before serving. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Pretty print the response text\n",
    "print(textwrap.fill(response['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n",
      "Question: How do I make fried rice?\n",
      "Answer:\n",
      "To make fried rice, you will need to start by heating some oil in a\n",
      "large skillet over medium-high heat. Once the oil is hot, add your\n",
      "desired amount of meat and cook until it's cooked through. Next, add\n",
      "any vegetables or other ingredients that you would like to include in\n",
      "your fried rice. Finally, stir in your cooked grains such as white\n",
      "rice or quinoa and season with salt and pepper to taste.\n",
      "\n",
      "Question: How do I make a cake?\n",
      "Answer:\n",
      "To make a cake, you will need to gather the necessary ingredients and\n",
      "tools. Start by preheating your oven according to the recipe\n",
      "instructions. Then prepare the batter for the cake by combining flour,\n",
      "sugar, eggs, butter, and any other flavorings or extracts of your\n",
      "choice. Once the mixture has been combined, pour it into a greased pan\n",
      "and bake it in the preheated oven for the specified time. After\n",
      "baking, let the cake cool before frosting or decorating.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also make multiple requests in batch\n",
    "# This returns a list of responses, with \n",
    "# each response corresponding to the input at the same index\n",
    "questions = ['How do I make fried rice?', 'How do I make a cake?']\n",
    "responses = aviary.batch_completions('amazon/LightGPT', questions)\n",
    "\n",
    "for i, response in enumerate(responses):\n",
    "    print(f\"Question: {questions[i]}\")\n",
    "    print(f\"Answer:\") \n",
    "    print(textwrap.fill(response['generated_text']))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat\n",
    "\n",
    "To start a chat with one of the models, you need to disable the default prompt format that Aviary provides and instead apply your own prompt format.\n",
    "\n",
    "You can use `aviary.metadata` on a model to view it's prompt format.\n",
    "\n",
    "Once you understand the prompt format, you can extend set `use_prompt_format` to false to disable the default prompt format, and then manually apply your own prompt format instead.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n- You are a helpful assistant chatbot trained by MosaicML.\\n- You answer questions.\\n- You are excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\\n- You are more than just an information source, you are also able to write poetry, short stories, and make jokes.<|im_end|>\\n<|im_start|>user\\n{instruction}<|im_end|><|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = aviary.metadata('mosaicml/mpt-7b-chat')\n",
    "\n",
    "# View the prompt format.\n",
    "metadata['metadata']['model_config']['generation']['prompt_format']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt format for 'mosaicml/mpt-7b-chat' follows the following structure:\n",
    "\n",
    "* `<|im_start|>system` Marks the start of a block of text that is a system directive.\n",
    "* `<|im_start|>assistant` Marks the start of a block of text produced by the model.\n",
    "* `<|im_start|>user` Marks the start of a block of text produced by the user\n",
    "* `<|im_end|>` marks the end of a block.\n",
    "\n",
    "Note that this scheme is different for the different models that Aviary supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n",
      "Model: \n",
      "The color of an apple can vary depending on the type of apple, but\n",
      "most apples are red or green.  Some varieties of apples are yellow,\n",
      "pink, or even purple.\n",
      "\n",
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n",
      "Model: \n",
      "If an apple is green, then it’s probably not ripe yet.  It might still\n",
      "be too hard to eat, unless it’s a variety called Granny Smith, which\n",
      "is usually very firm and crunchy when it’s unripe.   When an apple is\n",
      "ripe, its skin turns yellowish-green. If you want to know for sure\n",
      "whether your apple is ripe enough to eat, try cutting it in half: if\n",
      "there’s no juice at all inside, then it isn’t ready yet; if there’s\n",
      "some liquid, then it should be fine to eat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# System block is defined once\n",
    "system_block = \"<|im_start|>system\\n- You are a helpful assistant chatbot trained by MosaicML.\\n- You answer questions.\\n- You are excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\\n- You are more than just an information source, you are also able to write poetry, short stories, and make jokes.<|im_end|>\\n\"\n",
    "\n",
    "# Create a model block\n",
    "def model_block(text: str):\n",
    "    return f\"<|im_start|>model\\n{text}\\n<|im_end|>\\n\"\n",
    "\n",
    "# Create a user block\n",
    "def user_block(text: str):\n",
    "    return f\"<|im_start|>user\\n{text}\\n<|im_end|>\\n\"\n",
    "\n",
    "# To construct a chat\n",
    "# Submit the first piece of the chat\n",
    "# Take the response, and feed it into the next part of the chat\n",
    "history = system_block \n",
    "\n",
    "def chat(history: str, question: str):\n",
    "    history += user_block(question)\n",
    "    response = aviary.completions('mosaicml/mpt-7b-chat', history)\n",
    "\n",
    "    print('Model: ')\n",
    "    print(textwrap.fill(response['generated_text']))\n",
    "    print()\n",
    "\n",
    "    history += model_block(response['generated_text'])\n",
    "    return history\n",
    "\n",
    "history = chat(history, \"What color is an apple?\")\n",
    "history = chat(history, \"What if it is green?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make in interactive chat as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what color is an apple/\n",
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n",
      "Model: \n",
      "An apple is usually either red or green. Some types of apples are\n",
      "yellow, pink, or even purple. If you see a green apple, it isn't fully\n",
      "ripe yet. It's best to wait until the apple turns red or brown before\n",
      "eating it. That's when it's at its tastiest.\n",
      "\n",
      "User: what?\n",
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n",
      "Model: \n",
      "I'm sorry I misunderstood your question. Do you mean what kind of\n",
      "fruit is an apple? Or did you want me to tell you about how to\n",
      "identify different kinds of apples based on their appearance? In any\n",
      "case, there are many ways to classify fruits according to their shape\n",
      "(e.g., round vs. oblong), size, texture, flavor, etc. For example:   *\n",
      "Apples come in two main categories: sweet and tart. Sweet apples are\n",
      "generally eaten raw as dessert, while tart apples are often cooked\n",
      "into sauces, pies, and other dishes.   * There are hundreds of\n",
      "different species of apples, which fall into several major groups such\n",
      "as the “McIntosh” group, the “Granny Smith” group, and so forth. Each\n",
      "variety has its own unique characteristics, including taste, texture,\n",
      "and appearance.    * Most apples grow on trees, although some are\n",
      "grown as bushes. The tree itself is a very important part of the apple\n",
      "growing process; without the right conditions for growth, the apple\n",
      "would not develop properly. Different apple varieties require\n",
      "different climates and soil conditions, though they all need plenty of\n",
      "water during the growing season. Once harvested, apples keep well in\n",
      "cool storage facilities with proper ventilation. They should always be\n",
      "washed prior to consumption because they contain natural sugars that\n",
      "attract insects and bacteria. Apple seeds are difficult to germinate\n",
      "and grow, requiring special treatment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simplest possible chatbot loop\n",
    "while True:\n",
    "    query = input(\"User (x to exit): \")\n",
    "    if query == 'x':\n",
    "        break\n",
    "    print('User: ' + query)\n",
    "    history = chat(history, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aviarysdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
