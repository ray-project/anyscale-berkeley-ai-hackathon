{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "You will need to install aviary using the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aviary@ git+https://github.com/ray-project/aviary.git@sdk_update\n",
      "  Cloning https://github.com/ray-project/aviary.git (to revision sdk_update) to /private/var/folders/4j/z6dzqmms4xq0hsbh_7lx59f40000gn/T/pip-install-3p9asazc/aviary_e0451e61fc5f424e9439f2006360c350\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ray-project/aviary.git /private/var/folders/4j/z6dzqmms4xq0hsbh_7lx59f40000gn/T/pip-install-3p9asazc/aviary_e0451e61fc5f424e9439f2006360c350\n",
      "  Running command git checkout -b sdk_update --track origin/sdk_update\n",
      "  Switched to a new branch 'sdk_update'\n",
      "  branch 'sdk_update' set up to track 'origin/sdk_update'.\n",
      "  Resolved https://github.com/ray-project/aviary.git to commit 0b2c3716ab51bce5d2bb586647aae633dd93bd95\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typer>=0.9 (from aviary@ git+https://github.com/ray-project/aviary.git@sdk_update)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting rich (from aviary@ git+https://github.com/ray-project/aviary.git@sdk_update)\n",
      "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (4.6.3)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer>=0.9->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update)\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/tchordia/miniconda3/envs/aviarysdk/lib/python3.9/site-packages (from rich->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->aviary@ git+https://github.com/ray-project/aviary.git@sdk_update)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: aviary\n",
      "  Building wheel for aviary (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aviary: filename=aviary-0.0.2-py3-none-any.whl size=76723 sha256=4727e84cdbcfce3128f7df9d5826454c1e59c82d28e1ad17da1fc102528a5d7e\n",
      "  Stored in directory: /private/var/folders/4j/z6dzqmms4xq0hsbh_7lx59f40000gn/T/pip-ephem-wheel-cache-zjyhup50/wheels/88/e3/83/9f22ec0fc0ff079fbc83e01ffb66297a9bc3e4d2848cf68086\n",
      "Successfully built aviary\n",
      "Installing collected packages: mdurl, click, typer, markdown-it-py, rich, aviary\n",
      "Successfully installed aviary-0.0.2 click-8.1.3 markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.4.2 typer-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"aviary @ git+https://github.com/ray-project/aviary.git@sdk_update\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AVIARY_URL=https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com\n",
      "env: AVIARY_TOKEN=YOUR_TOKEN_HERE\n"
     ]
    }
   ],
   "source": [
    "%env AVIARY_URL=https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com\n",
    "%env AVIARY_TOKEN=YOUR_TOKEN_HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mosaicml/mpt-7b-instruct',\n",
       " 'amazon/LightGPT',\n",
       " 'databricks/dolly-v2-12b',\n",
       " 'CarperAI/stable-vicuna-13b-delta',\n",
       " 'OpenAssistant/falcon-7b-sft-top1-696',\n",
       " 'mosaicml/mpt-7b-chat',\n",
       " 'stabilityai/stablelm-tuned-alpha-7b',\n",
       " 'lmsys/vicuna-13b-delta-v1.1',\n",
       " 'mosaicml/mpt-7b-storywriter',\n",
       " 'h2oai/h2ogpt-oasst1-512-12b',\n",
       " 'OpenAssistant/oasst-sft-7-llama-30b-xor']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aviary\n",
    "\n",
    "# View all models available with aviary\n",
    "aviary.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_text': 'To make fried rice, start by heating up some oil in a pan over medium-high heat. Once it’s hot, add your desired amount of vegetables and/or meat to the pan. Cook for about 5 minutes until they are lightly browned. Then stir in cooked rice, soy sauce, garlic powder, and any other seasonings you like. Finally, reduce the heat to low and let the mixture cook for another 10-15 minutes before serving.',\n",
       " 'num_input_tokens': 35,\n",
       " 'num_input_tokens_batch': 35,\n",
       " 'num_generated_tokens': 94,\n",
       " 'num_generated_tokens_batch': 94,\n",
       " 'preprocessing_time': 0.0004903690000901406,\n",
       " 'generation_time': 1.4714834329997757,\n",
       " 'postprocessing_time': 0.0021571889997176186,\n",
       " 'generation_time_per_token': 0.011406848317827718,\n",
       " 'generation_time_per_token_batch': 0.011406848317827718,\n",
       " 'num_total_tokens': 129,\n",
       " 'num_total_tokens_batch': 129,\n",
       " 'total_time': 1.4741309909995834,\n",
       " 'total_time_per_token': 0.011427372023252585,\n",
       " 'total_time_per_token_batch': 0.011427372023252585}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query LightGPT model\n",
    "response = aviary.completions('amazon/LightGPT', 'How do I make fried rice?')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make fried rice, start by heating up some oil in a pan over medium-\n",
      "high heat. Once it’s hot, add your desired amount of vegetables and/or\n",
      "meat to the pan. Cook for about 5 minutes until they are lightly\n",
      "browned. Then stir in cooked rice, soy sauce, garlic powder, and any\n",
      "other seasonings you like. Finally, reduce the heat to low and let the\n",
      "mixture cook for another 10-15 minutes before serving.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "# Pretty print the response text\n",
    "print(textwrap.fill(response['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Aviary backend at:  https://aviary-oss-backend-primary-hackathon-nh1z6.cld-ldm5ez4edlp7yh4y.s.anyscaleuserdata.com/\n",
      "Question: How do I make fried rice?\n",
      "Answer:\n",
      "To make fried rice, you will need to start by heating some oil in a\n",
      "pan over medium-high heat. Once the oil has heated up, add your\n",
      "desired amount of rice and stir until it's coated with the oil. Next,\n",
      "add any other vegetables or meat that you want to include in your\n",
      "fried rice. Stir everything together until all the ingredients are\n",
      "well combined. Finally, reduce the heat to low and let the fried rice\n",
      "cook for about 10 minutes before serving.\n",
      "\n",
      "Question: How do I make a cake?\n",
      "Answer:\n",
      "To make a cake, you will need to gather all of your ingredients and\n",
      "follow the instructions for the recipe. Start by preheating your oven\n",
      "according to the recipe's instructions. Once it has reached the proper\n",
      "temperature, mix together the dry ingredients in one bowl and the wet\n",
      "ingredients in another. Then combine them together until everything is\n",
      "fully combined. Finally, pour the batter into a greased pan and bake\n",
      "it for the time specified in the recipe. Let the cake cool before\n",
      "frosting or decorating.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can also make multiple requests in batch\n",
    "# This returns a list of responses, with \n",
    "# each response corresponding to the input at the same index\n",
    "questions = ['How do I make fried rice?', 'How do I make a cake?']\n",
    "responses = aviary.batch_completions('amazon/LightGPT', questions)\n",
    "\n",
    "for i, response in enumerate(responses):\n",
    "    print(f\"Question: {questions[i]}\")\n",
    "    print(f\"Answer:\") \n",
    "    print(textwrap.fill(response['generated_text']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aviarysdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
